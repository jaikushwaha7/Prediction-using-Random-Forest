setwd("D:/Study/Hackathon analytics vidhya/Practice Loan Prediction")

train = read.csv(file.choose(), header =T, na.strings = "")
test = read.csv(file.choose(), header =T, na.strings = "")



# model 3 random forest
colnames(train)[colnames(train) == "train...13."] <- "Loan_Status" 
colnames(train)
rf = randomForest(Loan_Status ~ ., data = train[,2:13], ntree = 50)
rf$confusion # training data confusion matrix
pred = predict(rf, test[,2:12], type = "response")
class(pred)
head(pred)
data_test_pred = pred
summary(data_test_pred)
test$Loan_Status = data_test_pred
summary(test)
#colnames(test)[colnames(test) == "Loan_Status.ifelse.pred...2....pred...1....Y....N.."] <- "Loan_Status" 
test5 = subset(test, select = c(Loan_ID, Loan_Status))
summary(data_test_pred)
count(data_test_pred)
write.csv(test5, "submission3rf.csv",row.names = FALSE)


#caret::confusionMatrix(pred, truth)

# TUning Random forest
install.packages("ranger")
install.packages("mlr")
install.packages("mlr3")
library(mlr)
library(mlr3)
library(ranger)
learnerRF = makeLearner("regr.ranger", par.vals = list("num.trees" = 1000)) 
parsRF = makeParamSet(
  makeIntegerParam("mtry", lower = 0 , upper = 10)#, makeDiscreteParam("num.trees", 200)
)
tuneRF = makeTuneControlGrid() 
inner = makeResampleDesc("CV", iters = 10)
learnerRF = makeTuneWrapper(learnerRF, resampling = inner, par.set = parsRF,control = tuneRF, show.info = FALSE) 
model2 = train(learnerRF, train[,2:13] )


# Tuning RF 2
ptm = proc.time()
dim(train)
# Define task and learner
task <- makeClassifTask(id = "train",
                        data = train[,2:13],
                        target = "Loan_Status")

learner <- makeLearner("classif.ranger")

# Choose resampling strategy and define grid
rdesc <- makeResampleDesc("CV", iters = 5)
ps <- makeParamSet(makeIntegerParam("mtry", 3, 4),
                   makeDiscreteParam("num.trees", 200))

# Tune
res = tuneParams(learner, task, rdesc, par.set = ps,
                 control = makeTuneControlGrid())

# Train on entire dataset (using best hyperparameters)
lrn = setHyperPars(makeLearner("classif.ranger"), par.vals = res$x)
m = train(lrn, task)

print(m)
print(proc.time() - ptm) # ~6 seconds
head(m)

# Tuning 3 using caret
library(caret)
grid <-  expand.grid(mtry = c(3,4))

fitControl <- trainControl(method = "CV",
                           number = 5,
                           verboseIter = TRUE)

fit = train(
  x = train[,names(train)!='Loan_Status'],
  y = train[ , names(train) == 'Loan_Status'],
  method = 'ranger',
  num.trees = 200,
  tuneGrid = grid,
  min.node.size = 2,
  trControl = fitControl
)
print(fit)
# Error

# Tuning method 3

hyper_grid <- expand.grid(
  mtry       = 1:4,
  node_size  = 1:3,
  num.trees = seq(50,500,50),
  OOB_RMSE   = 0
)

system.time(
  for(i in 1:nrow(hyper_grid)) {
    # train model
    rf <- ranger(
      formula        = Loan_Status ~ .,
      data           = train[2:13],
      num.trees      = hyper_grid$num.trees[i],
      mtry           = hyper_grid$mtry[i],
      min.node.size  = hyper_grid$node_size[i],
      importance = 'impurity')
    # add OOB error to grid
    hyper_grid$OOB_RMSE[i] <- sqrt(rf$prediction.error)
  })


nrow(hyper_grid) # 120 models
position = which.min(hyper_grid$OOB_RMSE)
head(hyper_grid[order(hyper_grid$OOB_RMSE),],5)

# fit best model
rf.model <- ranger(Loan_Status ~ .,data = train[,2:13], num.trees = hyper_grid$num.trees[position], 
                   importance = 'impurity', probability = FALSE, 
                   min.node.size = hyper_grid$node_size[position], mtry = hyper_grid$mtry[position])
rf.model


pred = predict(rf.model, test[,2:12], type = "response")
class(pred)
head(pred)
data_test_pred = pred$predictions
summary(data_test_pred)
test$Loan_Status = data_test_pred
summary(test)
#colnames(test)[colnames(test) == "Loan_Status.ifelse.pred...2....pred...1....Y....N.."] <- "Loan_Status" 
test5 = subset(test, select = c(Loan_ID, Loan_Status))
summary(data_test_pred)
count(data_test_pred)
write.csv(test5, "submission4rf.csv",row.names = FALSE)



# TUning 4

# Tuning method 3

hyper_grid <- expand.grid(
  mtry       = 1:4,
  node_size  = 1:3,
  num.trees = seq(50,500,50),
  OOB_RMSE   = 0
)

system.time(
  for(i in 1:nrow(hyper_grid)) {
    # train model
    rf <- ranger(
      formula        = Loan_Status ~ .,
      data           = train[2:13],
      num.trees      = hyper_grid$num.trees[i],
      mtry           = hyper_grid$mtry[i],
      min.node.size  = hyper_grid$node_size[i],
      importance = 'impurity')
    # add OOB error to grid
    hyper_grid$OOB_RMSE[i] <- sqrt(rf$prediction.error)
  })


nrow(hyper_grid) # 120 models
position = which.min(hyper_grid$OOB_RMSE)
head(hyper_grid[order(hyper_grid$OOB_RMSE),],5)

# fit best model
rf.model <- ranger(Loan_Status ~ .,data = train[,2:13], num.trees = hyper_grid$num.trees[position], 
                   importance = 'impurity', probability = FALSE, 
                   min.node.size = hyper_grid$node_size[position], mtry = hyper_grid$mtry[position])
rf.model

rf.model1 <- randomForest(Loan_Status ~ .,data = train[,2:13], num.trees = hyper_grid$num.trees[position], 
                   probability = FALSE, 
                   min.node.size = hyper_grid$node_size[position], mtry = hyper_grid$mtry[position])

pred = predict(rf.model, test[,2:12], type = "response")
class(pred)
head(pred)
data_test_pred = pred$predictions
summary(data_test_pred)
test$Loan_Status = data_test_pred
summary(test)
#colnames(test)[colnames(test) == "Loan_Status.ifelse.pred...2....pred...1....Y....N.."] <- "Loan_Status" 
test5 = subset(test, select = c(Loan_ID, Loan_Status))
summary(data_test_pred)
count(data_test_pred)
write.csv(test5, "submission4rf.csv",row.names = FALSE)


pred = predict(rf.model1, test[,2:12], type = "response")
class(pred)
head(pred)
data_test_pred = pred
summary(data_test_pred)
test$Loan_Status = data_test_pred
summary(test)
#colnames(test)[colnames(test) == "Loan_Status.ifelse.pred...2....pred...1....Y....N.."] <- "Loan_Status" 
test5 = subset(test, select = c(Loan_ID, Loan_Status))
summary(data_test_pred)
count(data_test_pred)
write.csv(test5, "submission5rf.csv",row.names = FALSE)

# Shap for variable importance explanation
new_cust <- test[2,2:12] 


predict(rf.model1, new_cust, type = "prob")
#attr(predict(rf.model, newdata = new_cust, probability = TRUE), "probabilities")

exp_rf <- explain(rf.model1, data = train[,2:12])

ive_rf <- shap(exp_rf, new_observation = new_cust)
ive_rf

plot(ive_rf)

